{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9490e3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T09:02:36.471336Z",
     "iopub.status.busy": "2023-09-09T09:02:36.470779Z",
     "iopub.status.idle": "2023-09-09T09:02:40.624372Z",
     "shell.execute_reply": "2023-09-09T09:02:40.623205Z"
    },
    "papermill": {
     "duration": 4.170954,
     "end_time": "2023-09-09T09:02:40.627119",
     "exception": false,
     "start_time": "2023-09-09T09:02:36.456165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0bece9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T09:02:40.646613Z",
     "iopub.status.busy": "2023-09-09T09:02:40.645950Z",
     "iopub.status.idle": "2023-09-09T09:02:56.283209Z",
     "shell.execute_reply": "2023-09-09T09:02:56.281863Z"
    },
    "papermill": {
     "duration": 15.650089,
     "end_time": "2023-09-09T09:02:56.286181",
     "exception": false,
     "start_time": "2023-09-09T09:02:40.636092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c67c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T09:02:56.305566Z",
     "iopub.status.busy": "2023-09-09T09:02:56.305158Z",
     "iopub.status.idle": "2023-09-09T09:02:58.604485Z",
     "shell.execute_reply": "2023-09-09T09:02:58.602977Z"
    },
    "papermill": {
     "duration": 2.311436,
     "end_time": "2023-09-09T09:02:58.606521",
     "exception": true,
     "start_time": "2023-09-09T09:02:56.295085",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">numpy</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">np</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">cv2</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>20 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torcheval.metrics.functional</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> multiclass_f1_score, multiclass_accuracy           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">transformers</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> get_linear_schedule_with_warmup                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torchvision.transforms</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">T</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'torcheval'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m20\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mnumpy\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mnp\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mcv2\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m20 \u001b[94mfrom\u001b[0m \u001b[4;96mtorcheval\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmetrics\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mfunctional\u001b[0m \u001b[94mimport\u001b[0m multiclass_f1_score, multiclass_accuracy           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mtransformers\u001b[0m \u001b[94mimport\u001b[0m get_linear_schedule_with_warmup                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mtorchvision\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtransforms\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mT\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'torcheval'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List, Dict, Callable, Optional, Union, Tuple, Any\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_accuracy\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a20893",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cc9e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HeadV1(nn.Module):\n",
    "    def __init__(self, f_out: int, f_in: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label = nn.Sequential(\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.Dropout1d(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(f_in, f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.label(x)\n",
    "\n",
    "\n",
    "class HeadV4(nn.Module):\n",
    "    def __init__(self, f_out: int, f_in: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label = nn.Sequential(\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.Dropout1d(),\n",
    "            nn.Linear(f_in, f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.label(x)\n",
    "\n",
    "\n",
    "class HeadV5(nn.Module):\n",
    "    def __init__(self, f_out: int, f_in: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label = nn.Sequential(\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.Dropout1d(p=0.9),\n",
    "            nn.Linear(f_in, f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.label(x)\n",
    "\n",
    "\n",
    "class HeadV6(nn.Module):\n",
    "    def __init__(self, f_out: int, f_in: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label = nn.Sequential(\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.Dropout1d(p=0.75),\n",
    "            nn.Linear(f_in, f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.label(x)\n",
    "\n",
    "\n",
    "class HeadV2(nn.Module):\n",
    "    def __init__(self, f_out: int, f_in: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label = nn.Sequential(\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.Linear(f_in, f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.label(x)\n",
    "\n",
    "\n",
    "class HeadV3(nn.Module):\n",
    "    def __init__(self, f_out: int, f_in: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label = nn.Sequential(\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.Linear(f_in, f_in, bias=False),\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout1d(),\n",
    "            nn.Linear(f_in, f_in, bias=False),\n",
    "            nn.BatchNorm1d(f_in),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout1d(),\n",
    "            nn.Linear(f_in, f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.label(x)\n",
    "\n",
    "\n",
    "class CLIPClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes: int = 6,\n",
    "        model_name: str = \"ViT-L-14\",\n",
    "        data: str = \"datacomp_xl_s13b_b90k\",\n",
    "        head_version: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = open_clip.create_model_and_transforms(\n",
    "            model_name, pretrained=data\n",
    "        )[0].visual\n",
    "\n",
    "        if model_name == \"ViT-L-14\":\n",
    "            self.n = 768\n",
    "            self.lrs = dict(\n",
    "                back_lrs={\"8\": 1.25e-6, \"16\": 2.5e-6, \"20\": 5e-6, \"24\": 10e-6},\n",
    "                back_wd=1e-3,\n",
    "                hd_lr=3e-4,\n",
    "                hd_wd=1e-5,\n",
    "            )\n",
    "        elif model_name == \"ViT-H-14\":\n",
    "            self.n = 1024\n",
    "            self.lrs = {\n",
    "                \"back_lrs\": {\"10\": 1.25e-6, \"20\": 2.5e-6, \"26\": 5e-6, \"32\": 10e-6},\n",
    "                \"back_wd\": 1e-3,\n",
    "                \"hd_lr\": 3e-4,\n",
    "                \"hd_wd\": 1e-5,\n",
    "            }\n",
    "        elif model_name == \"ViT-B-16\":\n",
    "            self.n = 512\n",
    "            self.lrs = {\n",
    "                \"back_lrs\": {\"1\": 2.5e-6, \"7\": 5e-6, \"12\": 10e-6},\n",
    "                \"back_wd\": 1e-3,\n",
    "                \"hd_lr\": 3e-4,\n",
    "                \"hd_wd\": 1e-5,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        if head_version == 2:\n",
    "            self.label = HeadV2(n_classes, self.n)\n",
    "        elif head_version == 3:\n",
    "            self.label = HeadV3(n_classes, self.n)\n",
    "        elif head_version == 4:\n",
    "            self.label = HeadV4(n_classes, self.n)\n",
    "        elif head_version == 5:\n",
    "            self.label = HeadV5(n_classes, self.n)\n",
    "        elif head_version == 6:\n",
    "            self.label = HeadV6(n_classes, self.n)\n",
    "        else:\n",
    "            self.label = HeadV1(n_classes, self.n)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def forward(self, x: th.tensor) -> th.tensor:\n",
    "        x = self.backbone(x)\n",
    "        return self.label(x)\n",
    "\n",
    "    def get_parameter_section(self, parameters, lr=None, wd=None):\n",
    "        # https://github.com/IvanAer/G-Universal-CLIP\n",
    "        parameter_settings = []\n",
    "\n",
    "        lr_is_dict = isinstance(lr, dict)\n",
    "        wd_is_dict = isinstance(wd, dict)\n",
    "\n",
    "        layer_no = None\n",
    "        for n, p in parameters:\n",
    "            for split in n.split(\".\"):\n",
    "                if split.isnumeric():\n",
    "                    layer_no = int(split)\n",
    "\n",
    "            if not layer_no:\n",
    "                layer_no = 0\n",
    "\n",
    "            if lr_is_dict:\n",
    "                for k, v in lr.items():\n",
    "                    if layer_no < int(k):\n",
    "                        temp_lr = v\n",
    "                        break\n",
    "            else:\n",
    "                temp_lr = lr\n",
    "\n",
    "            if wd_is_dict:\n",
    "                for k, v in wd.items():\n",
    "                    if layer_no < int(k):\n",
    "                        temp_wd = v\n",
    "                        break\n",
    "            else:\n",
    "                temp_wd = wd\n",
    "\n",
    "            parameter_setting = {\"params\": p, \"lr\": temp_lr, \"weight_decay\": temp_wd}\n",
    "            parameter_settings.append(parameter_setting)\n",
    "        return parameter_settings\n",
    "\n",
    "    def get_learnable_params(self) -> list:\n",
    "        back_lrs = self.lrs[\"back_lrs\"]\n",
    "        back_wd = self.lrs[\"back_wd\"]\n",
    "        hd_lr = self.lrs[\"hd_lr\"]\n",
    "        hd_wd = self.lrs[\"hd_wd\"]\n",
    "\n",
    "        parameter_settings = []\n",
    "\n",
    "        if back_lrs and back_wd:\n",
    "            parameter_settings.extend(\n",
    "                self.get_parameter_section(\n",
    "                    [(n, p) for n, p in self.backbone.named_parameters()],\n",
    "                    lr=back_lrs,\n",
    "                    wd=back_wd,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        parameter_settings.extend(\n",
    "            self.get_parameter_section(\n",
    "                [(n, p) for n, p in self.label.named_parameters()], lr=hd_lr, wd=hd_wd\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return parameter_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46658307",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a7f62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_process(_: str) -> T.Compose:\n",
    "    return T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(\n",
    "                mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "                std=(0.26862954, 0.26130258, 0.27577711),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def aug(data_aug: str = \"image_net\") -> T.Compose:\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToPILImage(),\n",
    "            T.Resize(\n",
    "                size=(224, 224),\n",
    "                interpolation=T.InterpolationMode.BICUBIC,\n",
    "                antialias=True,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if data_aug == \"image_net\":\n",
    "        transform = T.Compose(\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "                T.Resize(\n",
    "                    size=(224, 224),\n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    elif data_aug == \"hca\":\n",
    "        aug8p3 = A.OneOf(\n",
    "            [\n",
    "                A.Sharpen(p=0.3),\n",
    "                A.ToGray(p=0.3),\n",
    "                A.CLAHE(p=0.3),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        )\n",
    "\n",
    "        blur = A.OneOf(\n",
    "            [\n",
    "                A.GaussianBlur(p=0.3),\n",
    "                A.MotionBlur(p=0.3),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        )\n",
    "\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.ShiftScaleRotate(\n",
    "                    rotate_limit=45,\n",
    "                    scale_limit=0.1,\n",
    "                    border_mode=cv2.BORDER_REFLECT,\n",
    "                    interpolation=cv2.INTER_CUBIC,\n",
    "                    p=0.5,\n",
    "                ),\n",
    "                A.Resize(224, 224, cv2.INTER_CUBIC),\n",
    "                aug8p3,\n",
    "                blur,\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ElasticTransform(p=0.5),\n",
    "                A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "            ]\n",
    "        )\n",
    "    elif data_aug == \"aug_mix\":\n",
    "        transform = T.Compose(\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                T.AugMix(),\n",
    "                T.Resize(\n",
    "                    size=(224, 224),\n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    elif data_aug == \"happy_whale\":\n",
    "        aug8p3 = A.OneOf(\n",
    "            [\n",
    "                A.Sharpen(p=0.3),\n",
    "                A.ToGray(p=0.3),\n",
    "                A.CLAHE(p=0.3),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        )\n",
    "\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.ShiftScaleRotate(\n",
    "                    rotate_limit=15,\n",
    "                    scale_limit=0.1,\n",
    "                    border_mode=cv2.BORDER_REFLECT,\n",
    "                    p=0.5,\n",
    "                ),\n",
    "                A.Resize(224, 224, cv2.INTER_CUBIC),\n",
    "                aug8p3,\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    elif data_aug == \"cut_out\":\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.ImageCompression(quality_lower=99, quality_upper=100),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.2,\n",
    "                    scale_limit=0.2,\n",
    "                    rotate_limit=10,\n",
    "                    border_mode=cv2.BORDER_REFLECT,\n",
    "                    p=0.7,\n",
    "                ),\n",
    "                A.Resize(224, 224, cv2.INTER_CUBIC),\n",
    "                A.Cutout(\n",
    "                    max_h_size=int(224 * 0.4),\n",
    "                    max_w_size=int(224 * 0.4),\n",
    "                    num_holes=1,\n",
    "                    p=0.5,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    elif data_aug == \"clip\":\n",
    "        transform = T.Compose(\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                T.RandomResizedCrop(\n",
    "                    size=(224, 224),\n",
    "                    scale=(0.9, 1.0),\n",
    "                    ratio=(0.75, 1.3333),\n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True,\n",
    "                ),\n",
    "                T.Resize(\n",
    "                    size=(224, 224),\n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    elif data_aug == \"clip+image_net\":\n",
    "        transform = T.Compose(\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "                T.RandomResizedCrop(\n",
    "                    size=(224, 224),\n",
    "                    scale=(0.9, 1.0),\n",
    "                    ratio=(0.75, 1.3333),\n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True,\n",
    "                ),\n",
    "                T.Resize(\n",
    "                    size=(224, 224),\n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return transform\n",
    "\n",
    "\n",
    "def read_image_cv2(f_name: str, gray_scale: bool = False) -> np.ndarray:\n",
    "    img = cv2.imread(\n",
    "        f_name, cv2.IMREAD_ANYCOLOR if not gray_scale else cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def class_balancing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    counts = df.class_label.value_counts().to_dict()\n",
    "    max_label = max(list(counts.items()), key=lambda x: x[1])\n",
    "\n",
    "    for key, value in counts.items():\n",
    "        if key == max_label[0]:\n",
    "            continue\n",
    "\n",
    "        df_label = df[df.class_label == key].sample(\n",
    "            n=max_label[1] - value, replace=True\n",
    "        )\n",
    "        df = pd.concat([df, df_label])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "class SimpleClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations_df: pd.DataFrame,\n",
    "        img_dir: str,\n",
    "        class_dict: dict,\n",
    "        transform: Optional[T.Compose] = None,\n",
    "        data_augment: Optional[Union[T.Compose, A.Compose]] = None,\n",
    "        class_balance: bool = True,\n",
    "    ):\n",
    "        self.df = annotations_df\n",
    "        if class_balance:\n",
    "            self.df = class_balancing(annotations_df)\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.class_dict = class_dict\n",
    "        self.transform = transform\n",
    "        self.data_augment = data_augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cv2.setNumThreads(6)\n",
    "\n",
    "        f_name, _, _, x_tl, y_tl, x_br, y_br, label = self.df.iloc[idx]\n",
    "\n",
    "        img = read_image_cv2(os.path.join(self.img_dir, f_name))\n",
    "        img_ = img[y_tl:y_br, x_tl:x_br, :]\n",
    "        if img_.shape[0] * img_.shape[1] != 0:\n",
    "            img = img_\n",
    "\n",
    "        if self.data_augment:\n",
    "            if isinstance(self.data_augment, A.Compose):\n",
    "                img = self.data_augment(image=img)[\"image\"]\n",
    "            else:\n",
    "                img = self.data_augment(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.class_dict:\n",
    "            label = self.class_dict[label]\n",
    "        return {\"img\": img, \"label\": label}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96213b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f89c7f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1(y_true: th.Tensor, y_pred: th.Tensor):\n",
    "    y_pred = th.round(y_pred)\n",
    "    tp = th.sum((y_true * y_pred).float(), dim=0)\n",
    "    tn = th.sum(((1 - y_true) * (1 - y_pred)).float(), dim=0)\n",
    "    fp = th.sum(((1 - y_true) * y_pred).float(), dim=0)\n",
    "    fn = th.sum((y_true * (1 - y_pred)).float(), dim=0)\n",
    "\n",
    "    p = tp / (tp + fp + 1e-7)\n",
    "    r = tp / (tp + fn + 1e-7)\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + 1e-7)\n",
    "    f1 = th.where(th.isnan(f1), th.zeros_like(f1), f1)\n",
    "    return th.mean(f1)\n",
    "\n",
    "\n",
    "def f1_loss(y_true: th.Tensor, y_pred: th.Tensor):\n",
    "    tp = th.sum((y_true * y_pred).float(), dim=0)\n",
    "    tn = th.sum(((1 - y_true) * (1 - y_pred)).float(), dim=0)\n",
    "    fp = th.sum(((1 - y_true) * y_pred).float(), dim=0)\n",
    "    fn = th.sum((y_true * (1 - y_pred)).float(), dim=0)\n",
    "\n",
    "    p = tp / (tp + fp + 1e-7)\n",
    "    r = tp / (tp + fn + 1e-7)\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + 1e-7)\n",
    "    f1 = th.where(th.isnan(f1), th.zeros_like(f1), f1)\n",
    "    return 1 - th.mean(f1)\n",
    "\n",
    "\n",
    "def accuracy(y1: th.Tensor, y2: th.Tensor):\n",
    "    y1_argmax = y1.argmax(dim=1)\n",
    "    y2_argmax = y2.argmax(dim=1)\n",
    "\n",
    "    correct_sum = th.sum(y1_argmax == y2_argmax)\n",
    "    return correct_sum / len(y1)\n",
    "\n",
    "\n",
    "class MosquitoClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes: int = 6,\n",
    "        model_name: str = \"ViT-L-14\",\n",
    "        dataset: str = \"datacomp_xl_s13b_b90k\",\n",
    "        freeze_backbones: bool = False,\n",
    "        head_version: int = 0,\n",
    "        warm_up_steps: int = 2000,\n",
    "        bs: int = 64,\n",
    "        data_aug: str = \"\",\n",
    "        loss_func: str = \"ce\",\n",
    "        epochs: int = 5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.cls = CLIPClassifier(n_classes, model_name, dataset, head_version)\n",
    "        if freeze_backbones:\n",
    "            self.freezebackbone()\n",
    "\n",
    "        self.scheduler = None\n",
    "        self.n_classes = n_classes\n",
    "        self.warm_up_steps = warm_up_steps\n",
    "        self.loss_func = loss_func\n",
    "\n",
    "        self.val_labels_t = []\n",
    "        self.val_labels_p = []\n",
    "\n",
    "        self.train_labels_t = []\n",
    "        self.train_labels_p = []\n",
    "\n",
    "    def freezebackbone(self) -> None:\n",
    "        for param in self.cls.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
    "        return self.cls(x)\n",
    "\n",
    "    def lr_schedulers(self):\n",
    "        # over-write this shit\n",
    "        return self.scheduler\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = th.optim.AdamW(self.cls.get_learnable_params())\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.warm_up_steps,\n",
    "            num_training_steps=12800,  # not sure what to set\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def compute_loss(self, label_t: th.Tensor, label_p: th.Tensor) -> th.Tensor:\n",
    "        if self.loss_func == \"f1\":\n",
    "            label_loss = f1_loss(label_t, th.nn.functional.softmax(label_p, dim=1))\n",
    "        elif self.loss_func == \"ce+f1\":\n",
    "            label_loss = f1_loss(\n",
    "                label_t, th.nn.functional.softmax(label_p, dim=1)\n",
    "            ) + nn.CrossEntropyLoss()(label_p, label_t)\n",
    "        else:\n",
    "            label_loss = nn.CrossEntropyLoss()(label_p, label_t)\n",
    "\n",
    "        return label_loss\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx) -> STEP_OUTPUT:\n",
    "        img, label_t = (\n",
    "            train_batch[\"img\"],\n",
    "            train_batch[\"label\"],\n",
    "        )\n",
    "\n",
    "        label_p = self.cls(img)\n",
    "        label_loss = self.compute_loss(label_t, label_p)\n",
    "\n",
    "        self.train_labels_t.append(label_t.detach().cpu())\n",
    "        self.train_labels_p.append(label_p.detach().cpu())\n",
    "\n",
    "        self.log(\"train_loss\", label_loss)\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return label_loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        label_p = th.concatenate(self.train_labels_p)\n",
    "        label_t = th.concatenate(self.train_labels_t)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_f1_score\": multiclass_f1_score(\n",
    "                    label_p,\n",
    "                    label_t.argmax(dim=1),\n",
    "                    num_classes=self.n_classes,\n",
    "                    average=\"macro\",\n",
    "                ),\n",
    "                \"train_multiclass_accuracy\": multiclass_accuracy(\n",
    "                    label_p,\n",
    "                    label_t.argmax(dim=1),\n",
    "                    num_classes=self.n_classes,\n",
    "                    average=\"macro\",\n",
    "                ),\n",
    "                \"train_accuracy\": accuracy(label_t, label_p),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.train_labels_t = []\n",
    "        self.train_labels_p = []\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx) -> STEP_OUTPUT:\n",
    "        img, label_t = (\n",
    "            val_batch[\"img\"],\n",
    "            val_batch[\"label\"],\n",
    "        )\n",
    "\n",
    "        label_p = self.cls(img)\n",
    "        label_loss = self.compute_loss(label_t, label_p)\n",
    "\n",
    "        self.val_labels_t.append(label_t.detach().cpu())\n",
    "        self.val_labels_p.append(label_p.detach().cpu())\n",
    "\n",
    "        self.log(\"val_loss\", label_loss)\n",
    "\n",
    "        return label_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        label_p = th.concatenate(self.val_labels_p)\n",
    "        label_t = th.concatenate(self.val_labels_t)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val_f1_score\": multiclass_f1_score(\n",
    "                    label_p,\n",
    "                    label_t.argmax(dim=1),\n",
    "                    num_classes=self.n_classes,\n",
    "                    average=\"macro\",\n",
    "                ),\n",
    "                \"val_multiclass_accuracy\": multiclass_accuracy(\n",
    "                    label_p,\n",
    "                    label_t.argmax(dim=1),\n",
    "                    num_classes=self.n_classes,\n",
    "                    average=\"macro\",\n",
    "                ),\n",
    "                \"val_accuracy\": accuracy(label_t, label_p),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.val_labels_t = []\n",
    "        self.val_labels_p = []\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        opt = self.optimizers(use_pl_optimizer=True)\n",
    "        self.log(\"lr\", opt.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9996d5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea976a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _default_callbacks() -> List[Callback]:\n",
    "    return [\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_f1_score\",\n",
    "            mode=\"max\",\n",
    "            save_top_k=2,\n",
    "            save_last=True,\n",
    "            filename=\"{epoch}-{val_loss}-{val_f1_score}-{val_multiclass_accuracy}\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "CLASS_DICT = {\n",
    "    \"albopictus\": th.tensor([1, 0, 0, 0, 0, 0], dtype=th.float),\n",
    "    \"culex\": th.tensor([0, 1, 0, 0, 0, 0], dtype=th.float),\n",
    "    \"japonicus/koreicus\": th.tensor([0, 0, 1, 0, 0, 0], dtype=th.float),\n",
    "    \"culiseta\": th.tensor([0, 0, 0, 1, 0, 0], dtype=th.float),\n",
    "    \"anopheles\": th.tensor([0, 0, 0, 0, 1, 0], dtype=th.float),\n",
    "    \"aegypti\": th.tensor([0, 0, 0, 0, 0, 1], dtype=th.float),\n",
    "}\n",
    "\n",
    "\n",
    "class ExperimentMosquitoClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dir: str,\n",
    "        annotations_csv: str,\n",
    "        class_dict: Dict[str, th.Tensor] = CLASS_DICT,\n",
    "    ):\n",
    "        self.img_dir = img_dir\n",
    "        self.annotations_csv = annotations_csv\n",
    "        self.class_dict = class_dict\n",
    "\n",
    "    def get_dataloaders(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        val_df: pd.DataFrame,\n",
    "        model_name: str,\n",
    "        data_aug: str,\n",
    "        bs: int,\n",
    "    ) -> List[DataLoader]:\n",
    "        transform = pre_process(model_name)\n",
    "\n",
    "        train_dataset = SimpleClassificationDataset(\n",
    "            train_df,\n",
    "            self.img_dir,\n",
    "            self.class_dict,\n",
    "            transform,\n",
    "            aug(data_aug),\n",
    "        )\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=bs,\n",
    "            shuffle=True,\n",
    "            num_workers=6,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        val_dataset = SimpleClassificationDataset(\n",
    "            val_df,\n",
    "            self.img_dir,\n",
    "            self.class_dict,\n",
    "            transform,\n",
    "            aug(\"resize\"),\n",
    "            class_balance=False,\n",
    "        )\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=bs,\n",
    "            shuffle=False,\n",
    "            num_workers=6,\n",
    "        )\n",
    "\n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        dataset: str,\n",
    "        bs: int,\n",
    "        head_version: int,\n",
    "        data_aug: str,\n",
    "        freeze_backbones: bool = False,\n",
    "        warm_up_steps: int = 2000,\n",
    "        epochs: int = 5,\n",
    "        create_callbacks: Callable[[], List[Callback]] = _default_callbacks,\n",
    "    ):\n",
    "        annotations_df = pd.read_csv(self.annotations_csv)\n",
    "        train_df, val_df = train_test_split(\n",
    "            annotations_df,\n",
    "            test_size=0.2,\n",
    "            stratify=annotations_df[\"class_label\"],\n",
    "            random_state=200,\n",
    "        )\n",
    "\n",
    "        train_dataloader, val_dataloader = self.get_dataloaders(\n",
    "            train_df, val_df, model_name, data_aug, bs\n",
    "        )\n",
    "\n",
    "        th.set_float32_matmul_precision(\"high\")\n",
    "        model = MosquitoClassifier(\n",
    "            model_name=model_name,\n",
    "            dataset=dataset,\n",
    "            freeze_backbones=freeze_backbones,\n",
    "            head_version=head_version,\n",
    "            warm_up_steps=warm_up_steps,\n",
    "            bs=bs,\n",
    "            data_aug=data_aug,\n",
    "            epochs=epochs,\n",
    "        )\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=\"gpu\",\n",
    "            precision=\"16-mixed\",\n",
    "            max_epochs=epochs,\n",
    "            logger=True,\n",
    "            deterministic=True,  # maybe we should add this\n",
    "            callbacks=create_callbacks(),\n",
    "        )\n",
    "\n",
    "        trainer.fit(\n",
    "            model=model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader,\n",
    "        )\n",
    "\n",
    "    def run_cross_validation(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        dataset: str,\n",
    "        bs: int,\n",
    "        head_version: int,\n",
    "        data_aug: str,\n",
    "        freeze_backbones: bool = False,\n",
    "        warm_up_steps: int = 2000,\n",
    "        epochs: int = 5,\n",
    "        n_splits: int = 5,\n",
    "        create_callbacks: Callable[[], List[Callback]] = _default_callbacks,\n",
    "    ):\n",
    "        annotations_df = pd.read_csv(self.annotations_csv)\n",
    "        skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "        for _, (train_index, val_index) in enumerate(\n",
    "            skf.split(annotations_df, annotations_df.class_label)\n",
    "        ):\n",
    "            train_df = annotations_df.iloc[train_index]\n",
    "            val_df = annotations_df.iloc[val_index]\n",
    "\n",
    "            train_dataloader, val_dataloader = self.get_dataloaders(\n",
    "                train_df, val_df, model_name, data_aug, bs\n",
    "            )\n",
    "\n",
    "            th.set_float32_matmul_precision(\"high\")\n",
    "            model = MosquitoClassifier(\n",
    "                model_name=model_name,\n",
    "                dataset=dataset,\n",
    "                freeze_backbones=freeze_backbones,\n",
    "                head_version=head_version,\n",
    "                warm_up_steps=warm_up_steps,\n",
    "                bs=bs,\n",
    "                data_aug=data_aug,\n",
    "                epochs=epochs,\n",
    "            )\n",
    "            trainer = pl.Trainer(\n",
    "                accelerator=\"gpu\",\n",
    "                precision=\"16-mixed\",\n",
    "                max_epochs=epochs,\n",
    "                logger=True,\n",
    "                callbacks=create_callbacks(),  # if I pass it as list of callbacks it doesn't work\n",
    "                deterministic=True,  # maybe we should add this\n",
    "                # TODO: we need some naming convention\n",
    "            )\n",
    "\n",
    "            trainer.fit(\n",
    "                model=model,\n",
    "                train_dataloaders=train_dataloader,\n",
    "                val_dataloaders=val_dataloader,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42f7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T08:48:52.513722Z",
     "iopub.status.busy": "2023-09-09T08:48:52.513240Z",
     "iopub.status.idle": "2023-09-09T08:49:09.224558Z",
     "shell.execute_reply": "2023-09-09T08:49:09.223044Z",
     "shell.execute_reply.started": "2023-09-09T08:48:52.513674Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ssh-keygen -t ed25519 -C \"felix@kemeth.de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0312e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T08:38:13.004150Z",
     "iopub.status.busy": "2023-09-09T08:38:13.003356Z",
     "iopub.status.idle": "2023-09-09T08:38:14.362458Z",
     "shell.execute_reply": "2023-09-09T08:38:14.360444Z",
     "shell.execute_reply.started": "2023-09-09T08:38:13.004104Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://fkemeth@github.com/HCA97/Mosquito-Classifiction.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced81acf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-12T07:07:05.744586Z",
     "iopub.status.busy": "2023-08-12T07:07:05.744176Z",
     "iopub.status.idle": "2023-08-12T07:07:05.752434Z",
     "shell.execute_reply": "2023-08-12T07:07:05.750946Z",
     "shell.execute_reply.started": "2023-08-12T07:07:05.744556Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a46a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T07:14:28.665795Z",
     "iopub.status.busy": "2023-08-12T07:14:28.665388Z",
     "iopub.status.idle": "2023-08-12T07:14:31.968044Z",
     "shell.execute_reply": "2023-08-12T07:14:31.966781Z",
     "shell.execute_reply.started": "2023-08-12T07:14:28.665763Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2cef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T07:19:53.973693Z",
     "iopub.status.busy": "2023-08-12T07:19:53.973307Z",
     "iopub.status.idle": "2023-08-12T07:19:54.134906Z",
     "shell.execute_reply": "2023-08-12T07:19:54.133367Z",
     "shell.execute_reply.started": "2023-08-12T07:19:53.973664Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f0e40",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.912579,
   "end_time": "2023-09-09T09:03:01.386981",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-09T09:02:23.474402",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
